#!/usr/bin/env python3
"""
Ollama Setup Script for JOAT
Helps users install and configure Ollama models for local AI processing.
"""

import subprocess
import sys
import os
import time
from ollama_client import OllamaModelManager
import json

def check_ollama_installation():
    """Check if Ollama is installed."""
    try:
        result = subprocess.run(['ollama', '--version'], 
                              capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print(f"‚úÖ Ollama is installed: {result.stdout.strip()}")
            return True
        else:
            print("‚ùå Ollama is installed but not working properly")
            return False
    except FileNotFoundError:
        print("‚ùå Ollama is not installed")
        return False
    except Exception as e:
        print(f"‚ùå Error checking Ollama: {e}")
        return False

def install_ollama():
    """Install Ollama if not already installed."""
    print("üì¶ Installing Ollama...")
    
    system = sys.platform
    if system == "darwin":  # macOS
        print("Installing Ollama on macOS...")
        try:
            subprocess.run(['curl', '-fsSL', 'https://ollama.ai/install.sh', '|', 'sh'], 
                         shell=True, check=True)
            print("‚úÖ Ollama installed successfully!")
            return True
        except subprocess.CalledProcessError as e:
            print(f"‚ùå Failed to install Ollama: {e}")
            return False
    elif system.startswith("linux"):
        print("Installing Ollama on Linux...")
        try:
            subprocess.run(['curl', '-fsSL', 'https://ollama.ai/install.sh', '|', 'sh'], 
                         shell=True, check=True)
            print("‚úÖ Ollama installed successfully!")
            return True
        except subprocess.CalledProcessError as e:
            print(f"‚ùå Failed to install Ollama: {e}")
            return False
    elif system == "win32":
        print("Installing Ollama on Windows...")
        print("Please download and install Ollama from: https://ollama.ai/download")
        return False
    else:
        print(f"‚ùå Unsupported operating system: {system}")
        return False

def start_ollama():
    """Start Ollama service."""
    print("üöÄ Starting Ollama service...")
    
    try:
        # Check if Ollama is already running
        result = subprocess.run(['ollama', 'list'], 
                              capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            print("‚úÖ Ollama is already running")
            return True
    except:
        pass
    
    try:
        # Start Ollama in background
        subprocess.Popen(['ollama', 'serve'], 
                        stdout=subprocess.DEVNULL, 
                        stderr=subprocess.DEVNULL)
        
        # Wait for Ollama to start
        print("‚è≥ Waiting for Ollama to start...")
        for i in range(30):  # Wait up to 30 seconds
            time.sleep(1)
            try:
                result = subprocess.run(['ollama', 'list'], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    print("‚úÖ Ollama started successfully!")
                    return True
            except:
                pass
        
        print("‚ùå Ollama failed to start within 30 seconds")
        return False
        
    except Exception as e:
        print(f"‚ùå Failed to start Ollama: {e}")
        return False

def setup_models():
    """Setup models for the default comprehensive (regular) profile."""
    print("\nüì¶ Installing default model profile: regular_sized_models")
    mapping_path = os.path.join(os.path.dirname(__file__), 'models_mapping.json')
    try:
        with open(mapping_path, 'r') as f:
            data = json.load(f)
    except Exception as e:
        print(f"‚ùå Failed to load mapping: {e}")
        return

    profile_key = 'regular_sized_models'
    profile_models = list((data.get(profile_key) or {}).values())
    if not profile_models:
        print("‚ùå No models found in regular_sized_models profile")
        return

    print(f"Models to install: {', '.join(profile_models)}")
    print("This will download data. Continue? (y/n): ", end="")
    response = input().lower().strip()
    if response != 'y':
        print("‚è≠Ô∏è  Skipping model setup")
        return

    manager = OllamaModelManager()
    # override recommended_models during this run to chosen profile
    manager.recommended_models = profile_models
    print("\nüîÑ Setting up models (this may take a while)...")
    results = manager.setup_models()
    print("\nüìä Setup Results:")
    for model, success in results.items():
        status = "‚úÖ" if success else "‚ùå"
        print(f"  {status} {model}")
    successful_models = [model for model, success in results.items() if success]
    if successful_models:
        print(f"\nüéâ Successfully set up {len(successful_models)} models!")
        print(f"Ready models: {', '.join(successful_models)}")
    else:
        print("\n‚ùå No models were set up successfully")

def main():
    """Main setup function."""
    print("üöÄ JOAT Ollama Setup")
    print("=" * 50)
    print("This script will help you set up Ollama for local AI processing.")
    print()
    
    # Check if Ollama is installed
    if not check_ollama_installation():
        print("\nüì¶ Ollama Installation Required")
        print("=" * 30)
        print("Ollama is not installed. Would you like to install it now? (y/n): ", end="")
        
        response = input().lower().strip()
        if response == 'y':
            if not install_ollama():
                print("\n‚ùå Failed to install Ollama automatically.")
                print("Please install Ollama manually from: https://ollama.ai/")
                return
        else:
            print("‚è≠Ô∏è  Skipping Ollama installation")
            print("Please install Ollama manually from: https://ollama.ai/")
            return
    
    # Start Ollama
    if not start_ollama():
        print("\n‚ùå Failed to start Ollama.")
        print("Please start Ollama manually by running: ollama serve")
        return
    
    # Setup models
    setup_models()
    
    print("\n" + "=" * 50)
    print("üéâ Setup complete!")
    print("\nYou can now run JOAT with:")
    print("  python main.py")
    print("\nOr test the system with:")
    print("  python example.py")

if __name__ == "__main__":
    main() 